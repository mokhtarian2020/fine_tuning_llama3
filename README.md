# fine_tuning_llama3
This project fine-tunes the LLaMA 3.1 model using LoRA adapters on an Alpaca-style dataset. It leverages PyTorch, Transformers, and PEFT for efficient, GPU-accelerated instruction tuning.
